### Question 1(20 marks)

If you need to build a distributed storage system, with approximately equal frequency of reading and writing, what can you draw on the experience of Kafka?  

[To explain your answer, it would be instructive to discuss this with Network/File IO, Disk IO, read/write of partition, High Availablity]

1. In terms of network/file IO, Kafka has adopted the techniquae of zero-copy and page cache and this will make the I/O much faster. Traditionally, if we want to read the data from file/network and write it into file/network, we have to pay much time on switching userspace to kernel space. This is mainly because we have to read the data from NIC buffer/disk buffer in kernel space to user space and load the data to kernel space in order to write it to DISK buffer/NIC buffer. However, Kafka use `sendfile` to directly immigrate the data from NIC buffer to disk buffer.
2. In terms of disk IO, sequence read and write plays a significant role in the high efficiency of Kafka. This is mainly because that disk is more friendly to sequence read and write. If the disk has to read/write some random data, the head has to continuously adjust its position and this will make read/write more time-consuming. In this case, Kafka taught us to try to accumulate your information in a batch and sequentially arrange it. 
3. With the approximately equal frequency of reading and write, the Kafka team decided to use the leader to read and write, rather than the leader write and followers read. In this circumstance, the leader has to deal with so many write requests. If the team of Kafka uses the architecture of the leader to write and followers read, due to the latency of sync, the user must read some dirty data and the reliability will decrease. 
4. To achieve the goal of high availability, Kafka has introduced to the concept of replica and ISR. The ISR represents the replica whose message is similar to the leader's, and when the leader is dead, Kafka will select one of those as the leader. So, if we want to make our system to reach the goal of high availability, we don't need every replica to have to be similar to the leader, and we just need some.

### Question 2

When doing streaming works, what is the difference between Storm and Spark Streaming?



### Question 3

Why Apache Storm cannot realize the exactly-once semantics? (Please think about the implement of exactly-once semantics in Kafka.) If you are an Apache Storm Committer, how will you achieve this goal?

The main reason of this issue is that Apache Storm has no state management. To be more specific, Apache Storm cannot perceive whether the system have processed the data or not. Also, Apache Storm cannot implement commit and rollback. 

Therefore, I think we should adopt two-phase commit(aka. 2pc). Like Kafka, we can use an object called Transaction Coordinator. Besides, every spout/bolt needs to report its state to the state manager and it will store those states to storage. When there are some errors occurred in a bolt/spout, the System will read the state from the storage and recover it immediately. Finally, when every bolt/spout in the system has successfully finished its pre-commit. The Transaction Coordinator will inform every spout/bolt that the transaction have finished. 



### Question 4

Dr. X argues that the bottleneck of mapreduce is disk I/O speed, so the reason why Apache Spark is faster than MapReduce in shuffle merely is that Apache Spark writes data to the memory rather than to the disk. Do you agree with Dr. X's statement? Why/ Why not?

[Hint: you need to think about the process of the shuffle in Spark and MapReduce. Whether your answer is the implement of Apache Spark is not important, but your answer should be reasonable and constructive advice is better.]

No, this statement is partially right. The bottleneck of mapreduce is network I/O and memory shortage, because of the heavy traffic and buffers to store unprocessed data. 

1. In MapReduce, map tasks will generate many buckets with small size, and this will make shuffle  more frequently. Howerver, Spark will merge those buckets into a single file and shuffle will be less, which means the job will be less time-consuming. 
2. Map tasks output the calculate result one by one, and use AppendOnlyMap and its aggregate algorithm to aggregate middle results, which greatly reduce the memory middle results used. Therefore, Spark will have more memory to do other mapreduce tasks. 
3. Reduce tasks will read middle results of map tasks one by one, and sort and aggreate those data in memory. Obiviously, Spark needn't consume memory to store unprocessed data. Therefore, Spark have more mermory to process other data and Spark becomes faster. 
4. Reduce tasks will pull the blocks according to the distribution of BlockManager Address, and blocks in the same BlockManger address will be accumulated. Spark will request those blocks in a batch, which will significately reduce the network I/O pressure. Therefore, Spark will have more network IO to do other mapreduce tasks. 



### Question 5

1. How we deal with big data? What are relationships of HDFS, MapReduce and HBase?

With data becomes larger and larger, we need to arrange it, process it and store it. Therefore, we use HBase to arrange those data, MapReduce to  process it and HDFS to store it.

HDFS v.s. BigTable

BigTable v.s. Dynamon
